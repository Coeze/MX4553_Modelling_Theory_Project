{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "x4MU3Lt9yp4T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4MU3Lt9yp4T",
        "outputId": "8a9a6c2d-84bb-40bd-f106-3b589a7a5598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MX4553_Modelling_Theory_Project'...\n",
            "remote: Enumerating objects: 497, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 497 (delta 50), reused 13 (delta 13), pack-reused 428 (from 4)\u001b[K\n",
            "Receiving objects: 100% (497/497), 11.27 MiB | 10.59 MiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Coeze/MX4553_Modelling_Theory_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1ZIKTmvwy90_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZIKTmvwy90_",
        "outputId": "3a1d53b3-5d71-44df-d029-4a507bd9be92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MX4553_Modelling_Theory_Project\n"
          ]
        }
      ],
      "source": [
        "%cd MX4553_Modelling_Theory_Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a9c7a83",
      "metadata": {
        "id": "3a9c7a83"
      },
      "source": [
        "# Model Calibration using Genetic Algorithm\n",
        "\n",
        "This notebook implements a genetic algorithm to optimize the parameters of the forest fire spread model using real fire data from the MTBS dataset. The optimization is based on the Sørensen index (also known as the Dice coefficient), which measures the spatial agreement between simulated and observed burned areas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4iMOeGSrzDmI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iMOeGSrzDmI",
        "outputId": "052657c3-5d8c-4f72-b669-6b9df0d479f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting matplotlib-scalebar\n",
            "  Downloading matplotlib_scalebar-0.9.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (3.7.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting noise\n",
            "  Downloading noise-1.2.2.zip (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona) (2025.1.31)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (8.1.8)\n",
            "Collecting click-plugins>=1.0 (from fiona)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting cligj>=0.5 (from fiona)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_scalebar-0.9.0-py3-none-any.whl (16 kB)\n",
            "Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: noise\n",
            "  Building wheel for noise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for noise: filename=noise-1.2.2-cp311-cp311-linux_x86_64.whl size=56283 sha256=4f141388c34ad12106b6fd2fb6e084f2336fd8b6cd1c74c445340bb574e26dc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/25/2e/af6d1bcc91a8f99af0f651f8718b9ab999720a21c6d4149091\n",
            "Successfully built noise\n",
            "Installing collected packages: noise, deap, cligj, click-plugins, affine, rasterio, fiona, matplotlib-scalebar\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 deap-1.4.2 fiona-1.10.1 matplotlib-scalebar-0.9.0 noise-1.2.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install fiona rasterio numpy pandas scikit-learn matplotlib matplotlib-scalebar geopandas pyproj shapely deap noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "59306860",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from src.model import CA\n",
        "\n",
        "from noise import snoise2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "35d305eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_size = (250, 250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3T-p_RSy7bJU",
      "metadata": {
        "id": "3T-p_RSy7bJU"
      },
      "outputs": [],
      "source": [
        "def generate_terrain_simplex(rows, cols, cell_size=30.0, min_elevation=100, max_elevation=1000,\n",
        "                           octaves=6, persistence=0.5, lacunarity=2.0, scale=100.0, seed=None):\n",
        "    \"\"\"\n",
        "    Generate realistic terrain elevation, slope, and aspect using Simplex noise.\n",
        "\n",
        "    Parameters:\n",
        "    - rows, cols: Dimensions of the grid\n",
        "    - cell_size: Size of each cell in meters\n",
        "    - min_elevation, max_elevation: Range of elevation values in meters\n",
        "    - octaves: Number of noise layers to combine (more = more detail)\n",
        "    - persistence: How much each octave contributes (amplitude multiplier)\n",
        "    - lacunarity: How frequency increases with each octave\n",
        "    - scale: Base scale of the noise (higher = more gradual changes)\n",
        "    - seed: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    - elevation: 2D numpy array of elevation values\n",
        "    - slope: 2D numpy array of slope values in degrees\n",
        "    - aspect: 2D numpy array of aspect values in degrees (0-360, 0=North)\n",
        "    \"\"\"\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # Generate elevation using simplex noise\n",
        "    elevation = np.zeros((rows, cols))\n",
        "\n",
        "    # For better performance, vectorize the coordinates\n",
        "    y_coords = np.linspace(0, scale, rows)\n",
        "    x_coords = np.linspace(0, scale, cols)\n",
        "\n",
        "    for octave in range(octaves):\n",
        "        frequency = lacunarity ** octave\n",
        "        amplitude = persistence ** octave\n",
        "\n",
        "        for i, y in enumerate(y_coords):\n",
        "            for j, x in enumerate(x_coords):\n",
        "                elevation[i, j] += amplitude * snoise2(\n",
        "                    y * frequency / scale,\n",
        "                    x * frequency / scale\n",
        "                )\n",
        "\n",
        "    # Normalize to 0-1 range\n",
        "    elevation_min = elevation.min()\n",
        "    elevation_max = elevation.max()\n",
        "    elevation = (elevation - elevation_min) / (elevation_max - elevation_min)\n",
        "\n",
        "    # Scale to desired elevation range\n",
        "    elevation = min_elevation + elevation * (max_elevation - min_elevation)\n",
        "\n",
        "    # Calculate slope and aspect from elevation using gradients\n",
        "    dy, dx = np.gradient(elevation, cell_size, cell_size)\n",
        "\n",
        "    # Calculate slope in degrees\n",
        "    # Slope is the angle of steepest descent\n",
        "    slope = np.degrees(np.arctan(np.sqrt(dx**2 + dy**2)))\n",
        "\n",
        "    # Calculate aspect in degrees (0-360, clockwise from north)\n",
        "    # Aspect is the direction of steepest descent\n",
        "    aspect = np.degrees(np.arctan2(-dx, dy))\n",
        "    # Convert to 0-360 range (0 = North)\n",
        "    aspect = np.where(aspect < 0, aspect + 360, aspect)\n",
        "\n",
        "    return elevation, slope, aspect\n",
        "\n",
        "# Generate terrain using simplex noise instead of random values\n",
        "elevation, slope, aspect = generate_terrain_simplex(\n",
        "    rows=grid_size[0],\n",
        "    cols=grid_size[1],\n",
        "    cell_size=1.0,\n",
        "    min_elevation=100,\n",
        "    max_elevation=1000,\n",
        "    scale=100.0,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Adjust humidity based on elevation (higher elevation = typically lower humidity)\n",
        "elevation_normalized = (elevation - 100) / 900  # Normalize to 0-1 range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "278cef15",
      "metadata": {
        "id": "278cef15"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "import json\n",
        "from scipy.stats import pearsonr\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "# Import our model from the src directory\n",
        "from src.model import CA\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a8a97b",
      "metadata": {
        "id": "d7a8a97b"
      },
      "source": [
        "## Finding Available Fire Data\n",
        "\n",
        "First, we'll identify the available fire datasets in the data directory that we can use for calibration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "32ed2e76",
      "metadata": {
        "id": "32ed2e76"
      },
      "outputs": [],
      "source": [
        "fires = ['alabama', 'arizona']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe43305",
      "metadata": {
        "id": "1fe43305"
      },
      "source": [
        "## Setting Up the Calibration Framework\n",
        "\n",
        "We'll define functions to evaluate model performance against real fire data using the Sørensen index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9dad19f0",
      "metadata": {
        "id": "9dad19f0"
      },
      "outputs": [],
      "source": [
        "def init_model_from_fire_data(fire, grid_size=(100, 100)):\n",
        "    \"\"\"Initialize a CA model from fire data\"\"\"\n",
        "    # Create a new CA model\n",
        "    model = CA(grid_size=grid_size)\n",
        "    model.load_terrain_data(slope, aspect, elevation)\n",
        "    model.load_mtbs_fire_data(fires[0])\n",
        "    success = model.initialise_ndvi_from_data(fire)\n",
        "    print(f\"Model initialized from {fire} data: {success}\")\n",
        "\n",
        "    return model if success else None\n",
        "\n",
        "def evaluate_model_performance(model, simulation_steps=20, params=None):\n",
        "    \"\"\"Run a model simulation and evaluate performance against actual fire data\"\"\"\n",
        "    if params:\n",
        "        # Set model parameters\n",
        "        model.p0 = params.get('p0', 0.5)\n",
        "        model.c1 = params.get('c1', 0.5)\n",
        "        model.c2 = params.get('c2', 0.5)\n",
        "\n",
        "    # Run the simulation\n",
        "    history = model.run_simulation(simulation_steps)\n",
        "\n",
        "    # Compare with actual burned area\n",
        "    if model.actual_burned_area is not None:\n",
        "        simulated_burned = (model.grid == 2).astype(int)  # Cells with state 2 are burnt\n",
        "\n",
        "        # Calculate Sørensen index (Dice coefficient)\n",
        "        true_positives = np.sum((simulated_burned == 1) & (model.actual_burned_area == 1))\n",
        "        false_positives = np.sum((simulated_burned == 1) & (model.actual_burned_area == 0))\n",
        "        false_negatives = np.sum((simulated_burned == 0) & (model.actual_burned_area == 1))\n",
        "\n",
        "        sorensen = 2 * true_positives / (2 * true_positives + false_positives + false_negatives) if (2 * true_positives + false_positives + false_negatives) > 0 else 0\n",
        "\n",
        "        return sorensen\n",
        "    else:\n",
        "        return 0.0  # No actual data to compare with"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a6be31b",
      "metadata": {
        "id": "4a6be31b"
      },
      "source": [
        "## Implementing the Genetic Algorithm for Parameter Optimization\n",
        "\n",
        "Now we'll implement a genetic algorithm to find the optimal parameters for our fire spread model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5a06dbfa",
      "metadata": {
        "id": "5a06dbfa"
      },
      "outputs": [],
      "source": [
        "# Define parameter ranges\n",
        "PARAM_RANGES = {\n",
        "    'p0': (0.1, 0.9),   # Base ignition probability\n",
        "    'c1': (0.1, 1.0),   # Wind effect parameter 1\n",
        "    'c2': (0.1, 1.0)    # Wind effect parameter 2\n",
        "}\n",
        "\n",
        "# Define genetic algorithm fitness function\n",
        "def evaluate_individual(individual, fire_folder, simulation_steps=20, grid_size=(100, 100)):\n",
        "    \"\"\"Evaluate fitness of a GA individual (parameter set)\"\"\"\n",
        "    # Convert GA individual to parameter dictionary\n",
        "    params = {\n",
        "        'p0': individual[0],\n",
        "        'c1': individual[1],\n",
        "        'c2': individual[2]\n",
        "    }\n",
        "\n",
        "    # Initialize model\n",
        "    model = init_model_from_fire_data(fire_folder, grid_size=grid_size)\n",
        "    if not model:\n",
        "        return (0.0,)  # Return tuple with single value for DEAP\n",
        "\n",
        "    # Evaluate with these parameters\n",
        "    sorensen = evaluate_model_performance(model, simulation_steps, params)\n",
        "\n",
        "    return (sorensen,)  # Return tuple with single value for DEAP\n",
        "\n",
        "# Setup genetic algorithm\n",
        "def setup_genetic_algorithm():\n",
        "    \"\"\"Setup DEAP genetic algorithm framework\"\"\"\n",
        "    # We want to maximize the Sørensen index\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "    toolbox = base.Toolbox()\n",
        "\n",
        "    # Register attribute generators\n",
        "    toolbox.register(\"attr_p0\", random.uniform, PARAM_RANGES['p0'][0], PARAM_RANGES['p0'][1])\n",
        "    toolbox.register(\"attr_c1\", random.uniform, PARAM_RANGES['c1'][0], PARAM_RANGES['c1'][1])\n",
        "    toolbox.register(\"attr_c2\", random.uniform, PARAM_RANGES['c2'][0], PARAM_RANGES['c2'][1])\n",
        "\n",
        "    # Register individual and population creation\n",
        "    toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                     (toolbox.attr_p0, toolbox.attr_c1, toolbox.attr_c2), n=1)\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "    # Register genetic operators\n",
        "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "    return toolbox\n",
        "\n",
        "# Check for DEAP creator reset\n",
        "if hasattr(creator, \"FitnessMax\"):\n",
        "    del creator.FitnessMax\n",
        "if hasattr(creator, \"Individual\"):\n",
        "    del creator.Individual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1159c7b",
      "metadata": {
        "id": "e1159c7b"
      },
      "source": [
        "## Running the Genetic Algorithm\n",
        "\n",
        "Now we'll run the genetic algorithm to find the optimal parameters for our fire spread model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22fd61c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e22fd61c",
        "outputId": "8a583518-a44b-4d2a-b1cf-cd458a52f4a2"
      },
      "outputs": [],
      "source": [
        "def run_genetic_algorithm(fire_folder, pop_size=30, n_gen=10, simulation_steps=20):\n",
        "    \"\"\"Run genetic algorithm to optimize model parameters\"\"\"\n",
        "    print(f\"Running genetic algorithm optimization for {fire_folder}...\")\n",
        "\n",
        "    # Setup GA\n",
        "    toolbox = setup_genetic_algorithm()\n",
        "\n",
        "    # Register evaluation function with the specific fire dataset\n",
        "    toolbox.register(\"evaluate\", evaluate_individual, fire_folder=fire_folder, simulation_steps=simulation_steps, grid_size=grid_size)\n",
        "\n",
        "    # Initialize population\n",
        "    pop = toolbox.population(n=pop_size)\n",
        "\n",
        "    # Initialize statistics\n",
        "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats.register(\"avg\", np.mean)\n",
        "    stats.register(\"std\", np.std)\n",
        "    stats.register(\"min\", np.min)\n",
        "    stats.register(\"max\", np.max)\n",
        "\n",
        "    # Run GA\n",
        "    hof = tools.HallOfFame(1)  # Keep track of best individual\n",
        "    pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.2, ngen=n_gen,\n",
        "                                      stats=stats, halloffame=hof, verbose=True)\n",
        "\n",
        "    # Get best individual\n",
        "    best_ind = hof[0]\n",
        "    best_params = {\n",
        "        'p0': best_ind[0],\n",
        "        'c1': best_ind[1],\n",
        "        'c2': best_ind[2]\n",
        "    }\n",
        "    best_fitness = best_ind.fitness.values[0]\n",
        "\n",
        "    print(f\"\\nOptimization complete.\")\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best Sørensen index: {best_fitness:.4f}\")\n",
        "\n",
        "    return best_params, best_fitness, logbook\n",
        "\n",
        "calibration_fire = fires[0]\n",
        "best_params, best_fitness, logbook = run_genetic_algorithm(\n",
        "    fire_folder=calibration_fire,\n",
        "    pop_size=20,\n",
        "    n_gen=5,     \n",
        "    simulation_steps=30\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "JLOWarME0mVx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLOWarME0mVx",
        "outputId": "092180bc-bc94-489f-847b-de81e6da34b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'p0': 0.8784926111834965, 'c1': 0.4406809394875182, 'c2': 0.5968365681459044}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb910d0",
      "metadata": {},
      "source": [
        "## Advanced Model Calibration Methods\n",
        "\n",
        "This section demonstrates more advanced methods for model calibration and parameter estimation using Bayesian methods, stochastic differential equations for environmental variables, and percolation theory integration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300afc61",
      "metadata": {},
      "source": [
        "### 1. Installing Required Dependencies\n",
        "\n",
        "The Bayesian parameter estimation requires PyMC3, Arviz, and Theano packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3da65d",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pymc arviz theano"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ff2902",
      "metadata": {},
      "source": [
        "### 2. Implementing Bayesian Parameter Estimation\n",
        "\n",
        "Unlike the genetic algorithm which finds a single optimal set of parameters, Bayesian methods provide full posterior distributions that quantify parameter uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c740250d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_bayesian_parameter_estimation(fire_folder, n_samples=1000, tune=500, simulation_steps=20, grid_size=(100, 100)):\n",
        "    \"\"\"Run Bayesian parameter estimation for model calibration\"\"\"\n",
        "    print(f\"Running Bayesian parameter estimation for {fire_folder}...\")\n",
        "    \n",
        "    # Initialize model\n",
        "    model = init_model_from_fire_data(fire_folder, grid_size)\n",
        "    if not model:\n",
        "        return None, None\n",
        "    \n",
        "    # Define observations dictionary\n",
        "    observations = {\n",
        "        'simulation_steps': simulation_steps,\n",
        "        'initial_fire_points': [(model.rows//2, model.cols//2)]  \n",
        "    }\n",
        "    \n",
        "    # Set custom priors based on prior knowledge or GA results\n",
        "    prior_params = {\n",
        "        'p0_alpha': 3.0,    # Shape parameters for Beta distribution, centered around 0.6\n",
        "        'p0_beta': 2.0,     # These parameters give a mean of 0.6\n",
        "        'c1_mu': 0.5,       # Mean for Normal distribution\n",
        "        'c1_sigma': 0.2,    # Standard deviation\n",
        "        'c2_mu': 0.5,       # Mean for Normal distribution\n",
        "        'c2_sigma': 0.2     # Standard deviation\n",
        "    }\n",
        "    \n",
        "    # Run Bayesian parameter estimation\n",
        "    print(\"Starting MCMC sampling - this may take some time...\")\n",
        "    trace, summary = model.bayesian_parameter_estimation(\n",
        "        observations=observations,\n",
        "        prior_params=prior_params,\n",
        "        n_samples=n_samples,\n",
        "        tune=tune\n",
        "    )\n",
        "    \n",
        "    if trace is None:\n",
        "        print(\"Error: Bayesian estimation failed. Please install required packages.\")\n",
        "        return None, None\n",
        "    \n",
        "    # Extract optimal parameters from posterior means\n",
        "    best_params = {\n",
        "        'p0': summary.loc['p0', 'mean'],\n",
        "        'c1': summary.loc['c1', 'mean'],\n",
        "        'c2': summary.loc['c2', 'mean']\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nBayesian estimation complete.\")\n",
        "    print(f\"Optimal parameters (posterior means): {best_params}\")\n",
        "    print(f\"Parameter 95% credible intervals:\")\n",
        "    print(f\"p0: [{summary.loc['p0', 'hdi_3%']:.4f}, {summary.loc['p0', 'hdi_97%']:.4f}]\")\n",
        "    print(f\"c1: [{summary.loc['c1', 'hdi_3%']:.4f}, {summary.loc['c1', 'hdi_97%']:.4f}]\")\n",
        "    print(f\"c2: [{summary.loc['c2', 'hdi_3%']:.4f}, {summary.loc['c2', 'hdi_97%']:.4f}]\")\n",
        "    \n",
        "    return best_params, trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4c3740cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Bayesian parameter estimation for alabama...\n",
            "(187, 62)\n",
            "Loaded burn perimeter shapefile: data/al3039808817220190514/al3039808817220190514_20190513_20190528_burn_bndy.shp\n",
            "Loaded DNBR raster: data/al3039808817220190514/al3039808817220190514_20190513_20190528_dnbr.tif\n",
            "Initializing from alabama fire\n",
            "Loaded burn perimeter successfully\n",
            "Resampling DNBR data from (299, 287) to (250, 250)\n",
            "Estimated NDVI from DNBR data\n",
            "Model initialized from alabama data: True\n",
            "Starting MCMC sampling - this may take some time...\n",
            "Error: This method requires PyMC3, Arviz, and Theano. Please install with:\n",
            "pip install pymc3 arviz theano\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable NoneType object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run Bayesian parameter estimation with a small number of samples for demonstration\u001b[39;00m\n\u001b[0;32m      2\u001b[0m calibration_fire \u001b[38;5;241m=\u001b[39m fires[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m bayesian_params, trace \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bayesian_parameter_estimation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfire_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalibration_fire\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Small sample size for demonstration\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Small tuning phase for demonstration\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_size\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[8], line 28\u001b[0m, in \u001b[0;36mrun_bayesian_parameter_estimation\u001b[1;34m(fire_folder, n_samples, tune, simulation_steps, grid_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Run Bayesian parameter estimation\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting MCMC sampling - this may take some time...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m trace, summary \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbayesian_parameter_estimation(\n\u001b[0;32m     29\u001b[0m     observations\u001b[38;5;241m=\u001b[39mobservations,\n\u001b[0;32m     30\u001b[0m     prior_params\u001b[38;5;241m=\u001b[39mprior_params,\n\u001b[0;32m     31\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39mn_samples,\n\u001b[0;32m     32\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Bayesian estimation failed. Please install required packages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "# Run Bayesian parameter estimation with a small number of samples for demonstration\n",
        "calibration_fire = fires[0]\n",
        "bayesian_params, trace = run_bayesian_parameter_estimation(\n",
        "    fire_folder=calibration_fire,\n",
        "    n_samples=500,    # Small sample size for demonstration\n",
        "    tune=200,         # Small tuning phase for demonstration\n",
        "    simulation_steps=20,\n",
        "    grid_size=grid_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ea4d0c5",
      "metadata": {},
      "source": [
        "### 3. Visualizing Parameter Posterior Distributions\n",
        "\n",
        "One advantage of Bayesian estimation is that we get full posterior distributions, showing uncertainty in parameter estimates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a45f382",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trace' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01marviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maz\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Plot posterior distributions if trace is available\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrace\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Plot trace and posterior distributions\u001b[39;00m\n\u001b[32m      6\u001b[39m     az.plot_trace(trace, var_names=[\u001b[33m'\u001b[39m\u001b[33mp0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mc1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mc2\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m     plt.tight_layout()\n",
            "\u001b[31mNameError\u001b[39m: name 'trace' is not defined"
          ]
        }
      ],
      "source": [
        "import arviz as az\n",
        "\n",
        "# Plot posterior distributions if trace is available\n",
        "if trace is not None:\n",
        "    # Plot trace and posterior distributions\n",
        "    az.plot_trace(trace, var_names=['p0', 'c1', 'c2'])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot parameter correlations\n",
        "    az.plot_pair(trace, var_names=['p0', 'c1', 'c2'])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beb988b5",
      "metadata": {},
      "source": [
        "### 4. Comparing Calibration Methods\n",
        "\n",
        "We can compare the parameters estimated by the genetic algorithm and the Bayesian approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef71fe89",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare parameters from both methods\n",
        "if bayesian_params and best_params:\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Genetic Algorithm': [best_params['p0'], best_params['c1'], best_params['c2']],\n",
        "        'Bayesian Estimation (Mean)': [bayesian_params['p0'], bayesian_params['c1'], bayesian_params['c2']]\n",
        "    }, index=['p0', 'c1', 'c2'])\n",
        "    \n",
        "    display(comparison_df)\n",
        "    \n",
        "    # Visualize parameter comparison\n",
        "    comparison_df.plot(kind='bar', figsize=(10, 6))\n",
        "    plt.title('Comparison of Parameter Estimation Methods')\n",
        "    plt.ylabel('Parameter Value')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2cb2265",
      "metadata": {},
      "source": [
        "### 5. Dynamic Environmental Conditions using Stochastic Differential Equations\n",
        "\n",
        "We can make our simulations more realistic by allowing environmental conditions to evolve stochastically during the simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3672695",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_sde_simulation(model, steps=30, dt=0.1):\n",
        "    \"\"\"Run simulation with stochastic environmental conditions\"\"\"\n",
        "    history = [np.copy(model.grid)]\n",
        "    env_history = []\n",
        "    \n",
        "    # Initial environmental conditions\n",
        "    env_history.append({\n",
        "        'wind_speed': model.wind_speed,\n",
        "        'wind_direction': model.wind_direction,\n",
        "        'temperature': model.temperature,\n",
        "        'humidity': np.mean(model.humidity),\n",
        "        'precipitation': model.precipitation\n",
        "    })\n",
        "    \n",
        "    for step in range(steps):\n",
        "        # Update environmental conditions stochastically\n",
        "        env_conditions = model.update_environmental_conditions(dt=dt)\n",
        "        env_history.append(env_conditions)\n",
        "        \n",
        "        # Update fire spread\n",
        "        model.update()\n",
        "        history.append(np.copy(model.grid))\n",
        "        \n",
        "        # Stop if no more burning cells\n",
        "        if not np.any(model.grid == 1):\n",
        "            print(f\"Fire contained after {step+1} steps\")\n",
        "            break\n",
        "    \n",
        "    return history, env_history\n",
        "\n",
        "def visualize_environmental_dynamics(env_history):\n",
        "    \"\"\"Visualize how environmental conditions change over the simulation\"\"\"\n",
        "    env_df = pd.DataFrame(env_history)\n",
        "    \n",
        "    fig, axs = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "    \n",
        "    # Plot wind speed and direction\n",
        "    axs[0].plot(env_df['wind_speed'], 'b-', label='Wind Speed (m/s)')\n",
        "    axs[0].set_ylabel('Wind Speed (m/s)')\n",
        "    axs[0].set_title('Wind Speed Evolution')\n",
        "    axs[0].grid(True)\n",
        "    \n",
        "    axs[1].plot(env_df['wind_direction'], 'g-', label='Wind Direction (°)')\n",
        "    axs[1].set_ylabel('Wind Direction (°)')\n",
        "    axs[1].set_title('Wind Direction Evolution')\n",
        "    axs[1].grid(True)\n",
        "    \n",
        "    # Plot temperature, humidity, and precipitation\n",
        "    ax2 = axs[2]\n",
        "    ax2.plot(env_df['temperature'], 'r-', label='Temperature (°F)')\n",
        "    ax2.set_ylabel('Temperature (°F)', color='r')\n",
        "    ax2.tick_params(axis='y', labelcolor='r')\n",
        "    ax2.set_title('Temperature, Humidity, and Precipitation Evolution')\n",
        "    ax2.set_xlabel('Simulation Step')\n",
        "    ax2.grid(True)\n",
        "    \n",
        "    ax3 = ax2.twinx()\n",
        "    ax3.plot(env_df['humidity'], 'b--', label='Humidity (%)')\n",
        "    ax3.plot(env_df['precipitation'], 'g-.', label='Precipitation (mm)')\n",
        "    ax3.set_ylabel('Humidity (%) / Precipitation (mm)')\n",
        "    \n",
        "    # Add legend\n",
        "    lines1, labels1 = ax2.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax3.get_legend_handles_labels()\n",
        "    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0b51b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model with optimal parameters (from either method)\n",
        "optimal_params = bayesian_params if bayesian_params else best_params\n",
        "model = init_model_from_fire_data(calibration_fire)\n",
        "\n",
        "if model and optimal_params:\n",
        "    # Set optimal parameters\n",
        "    model.p0 = optimal_params['p0']\n",
        "    model.c1 = optimal_params['c1']\n",
        "    model.c2 = optimal_params['c2']\n",
        "    \n",
        "    # Set initial environmental conditions\n",
        "    model.set_environmental_data(wind_speed=5.0, wind_direction=225.0, \n",
        "                               temperature=50, humidity=5, fire_direction=20)\n",
        "    \n",
        "    # Run simulation with stochastic environmental conditions\n",
        "    print(\"Running simulation with stochastic environmental conditions...\")\n",
        "    history, env_history = run_sde_simulation(model, steps=30, dt=0.1)\n",
        "    \n",
        "    # Visualize fire spread\n",
        "    model.visualize_simulation(history)\n",
        "    \n",
        "    # Visualize environmental dynamics\n",
        "    visualize_environmental_dynamics(env_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a493ae",
      "metadata": {},
      "source": [
        "### 6. Analyzing Percolation Effects on Fire Spread\n",
        "\n",
        "The percolation threshold integration allows us to better model how fire spreads through heterogeneous landscapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e69188",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_percolation_thresholds(model):\n",
        "    \"\"\"Visualize percolation thresholds across the landscape\"\"\"\n",
        "    # Calculate percolation thresholds for the entire grid\n",
        "    pc_map = np.zeros((model.rows, model.cols))\n",
        "    exceeds_map = np.zeros((model.rows, model.cols))\n",
        "    \n",
        "    for r in range(model.rows):\n",
        "        for c in range(model.cols):\n",
        "            pc, exceeds = model.calculate_percolation_threshold(r, c)\n",
        "            pc_map[r, c] = pc\n",
        "            exceeds_map[r, c] = 1 if exceeds else 0\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    \n",
        "    # Plot the NDVI (fuel density)\n",
        "    im1 = axs[0].imshow(model.ndvi, cmap='YlGn')\n",
        "    axs[0].set_title('Fuel Density (NDVI)')\n",
        "    plt.colorbar(im1, ax=axs[0])\n",
        "    \n",
        "    # Plot the percolation thresholds\n",
        "    im2 = axs[1].imshow(pc_map, cmap='plasma')\n",
        "    axs[1].set_title('Percolation Thresholds')\n",
        "    plt.colorbar(im2, ax=axs[1])\n",
        "    \n",
        "    # Plot areas that exceed threshold\n",
        "    im3 = axs[2].imshow(exceeds_map, cmap='RdYlGn')\n",
        "    axs[2].set_title('Areas Exceeding Percolation Threshold')\n",
        "    plt.colorbar(im3, ax=axs[2], ticks=[0, 1], \n",
        "                 label='0: Below Threshold, 1: Above Threshold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return pc_map, exceeds_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d57f9dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze percolation thresholds in the model\n",
        "if model:\n",
        "    print(\"Analyzing percolation thresholds across the landscape...\")\n",
        "    pc_map, exceeds_map = visualize_percolation_thresholds(model)\n",
        "    \n",
        "    # Calculate statistics\n",
        "    exceed_percentage = np.mean(exceeds_map) * 100\n",
        "    avg_threshold = np.mean(pc_map)\n",
        "    \n",
        "    print(f\"Average percolation threshold: {avg_threshold:.4f}\")\n",
        "    print(f\"Percentage of landscape exceeding threshold: {exceed_percentage:.1f}%\")\n",
        "    \n",
        "    # Check if there are natural firebreaks (areas below threshold surrounding higher-risk areas)\n",
        "    from scipy import ndimage\n",
        "    firebreak_kernel = np.ones((3, 3))\n",
        "    potential_firebreaks = ndimage.binary_dilation(exceeds_map > 0) & ~(exceeds_map > 0)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(potential_firebreaks, cmap='Reds')\n",
        "    plt.title('Potential Natural Firebreaks (Areas Below Threshold Adjacent to High-Risk Areas)')\n",
        "    plt.colorbar(label='Potential Firebreak')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6cf69b",
      "metadata": {},
      "source": [
        "### 7. Comparing Fire Spread Models: With and Without Percolation\n",
        "\n",
        "We can compare how fire spreads with and without percolation theory to see the difference in patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2044f3ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_comparative_simulations(fire_folder, params, with_sde=False):\n",
        "    \"\"\"Run simulations with and without percolation for comparison\"\"\"\n",
        "    # Initialize two identical models\n",
        "    model1 = init_model_from_fire_data(fire_folder)  # With percolation (default)\n",
        "    \n",
        "    # Temporarily modify the calculate_ignition_probability method to disable percolation\n",
        "    # by patching the method in a second model instance\n",
        "    model2 = init_model_from_fire_data(fire_folder)  # Will disable percolation\n",
        "    \n",
        "    if not model1 or not model2:\n",
        "        return None, None\n",
        "    \n",
        "    # Set parameters for both models\n",
        "    for model in [model1, model2]:\n",
        "        model.p0 = params['p0']\n",
        "        model.c1 = params['c1']\n",
        "        model.c2 = params['c2']\n",
        "        model.set_environmental_data(wind_speed=5.0, wind_direction=225.0, \n",
        "                                  temperature=50, humidity=5, fire_direction=20)\n",
        "    \n",
        "    # Store original method reference\n",
        "    original_method = model2.calculate_ignition_probability\n",
        "    \n",
        "    # Define a modified version without percolation effects\n",
        "    def modified_ignition_probability(self, row, col):\n",
        "        \"\"\"Calculate ignition probability without percolation effects\"\"\"\n",
        "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
        "            return 0.0\n",
        "        \n",
        "        if self.grid[row, col] != 0:  # Already burning or burnt\n",
        "            return 0.0\n",
        "        \n",
        "        highest_veg_prob = 0.0\n",
        "        has_burning_neighbors = False\n",
        "        \n",
        "        for dr in [-1, 0, 1]:\n",
        "            for dc in [-1, 0, 1]:\n",
        "                if dr == 0 and dc == 0:\n",
        "                    continue\n",
        "                nr, nc = row + dr, col + dc\n",
        "                if 0 <= nr < self.rows and 0 <= nc < self.cols and self.grid[nr, nc] == 1:\n",
        "                    highest_veg_prob = max(highest_veg_prob, \n",
        "                                          self.fuel_model[self.fuel_type[nr, nc], \n",
        "                                                         self.fuel_type[row, col]])\n",
        "                    has_burning_neighbors = True\n",
        "            if has_burning_neighbors:\n",
        "                break\n",
        "        \n",
        "        if not has_burning_neighbors:\n",
        "            return 0.0\n",
        "        \n",
        "        # Calculate standard environmental effects\n",
        "        wind_effects = self.wind_effect(self.c1, self.c2)\n",
        "        topography_effects = self.topography_effect(self.slope[row, col])\n",
        "        humidity_effects = self.humidity_effect(humidity=self.humidity)\n",
        "        temperature_effects = self.temperature_effect(temperature=self.temperature)\n",
        "        precipitation_effect = self.precipitation_effect(self.precipitation)\n",
        "        p_density = self.ndvi[row, col] * 0.5 + 0.5\n",
        "        \n",
        "        # Calculate base probability without percolation factor\n",
        "        base_probability = self.p0 * (1+highest_veg_prob) * (1+p_density) * wind_effects * topography_effects\n",
        "        \n",
        "        # Apply temperature and moisture effects\n",
        "        moisture_effect = 1.0 / (humidity_effects * precipitation_effect)\n",
        "        moisture_effect = min(moisture_effect, 5.0)  # Cap the effect\n",
        "        \n",
        "        # Final probability without percolation\n",
        "        adjusted_probability = base_probability * temperature_effects * moisture_effect\n",
        "        \n",
        "        return min(1, adjusted_probability)\n",
        "    \n",
        "    # Patch the method for model2 - this is a somewhat hacky way to replace the method\n",
        "    import types\n",
        "    model2.calculate_ignition_probability = types.MethodType(modified_ignition_probability, model2)\n",
        "    \n",
        "    # Run simulations\n",
        "    print(\"Running simulation with percolation effects...\")\n",
        "    if with_sde:\n",
        "        history1, _ = run_sde_simulation(model1)\n",
        "    else:\n",
        "        history1 = model1.run_simulation(30)\n",
        "    \n",
        "    print(\"Running simulation without percolation effects...\")\n",
        "    if with_sde:\n",
        "        history2, _ = run_sde_simulation(model2)\n",
        "    else:\n",
        "        history2 = model2.run_simulation(30)\n",
        "    \n",
        "    # Restore original method to avoid side effects\n",
        "    model2.calculate_ignition_probability = original_method\n",
        "    \n",
        "    return history1, history2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3101f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run comparative simulations\n",
        "if optimal_params:\n",
        "    history_with_percolation, history_without_percolation = run_comparative_simulations(\n",
        "        fire_folder=calibration_fire,\n",
        "        params=optimal_params,\n",
        "        with_sde=False  # Set to True to include stochastic environmental conditions\n",
        "    )\n",
        "    \n",
        "    if history_with_percolation and history_without_percolation:\n",
        "        # Visualize final fire perimeters side by side\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
        "        \n",
        "        # With percolation\n",
        "        final_with = history_with_percolation[-1]\n",
        "        axs[0].imshow((final_with == 2), cmap='Reds')\n",
        "        axs[0].set_title('Fire Spread WITH Percolation Effects')\n",
        "        axs[0].axis('off')\n",
        "        \n",
        "        # Without percolation\n",
        "        final_without = history_without_percolation[-1]\n",
        "        axs[1].imshow((final_without == 2), cmap='Reds')\n",
        "        axs[1].set_title('Fire Spread WITHOUT Percolation Effects')\n",
        "        axs[1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Compare fire sizes\n",
        "        burned_with = np.sum(final_with == 2)\n",
        "        burned_without = np.sum(final_without == 2)\n",
        "        print(f\"Burned area WITH percolation: {burned_with} cells\")\n",
        "        print(f\"Burned area WITHOUT percolation: {burned_without} cells\")\n",
        "        print(f\"Difference: {abs(burned_with - burned_without)} cells \n",
        "({100*abs(burned_with - burned_without)/max(burned_with, burned_without):.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d0389d",
      "metadata": {},
      "source": [
        "### 8. Saving and Loading Calibrated Model Parameters\n",
        "\n",
        "Save the calibrated parameters for future use in other models and simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b29ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model_parameters(params, method, file_path='calibrated_params.json'):\n",
        "    \"\"\"Save calibrated parameters to JSON file\"\"\"\n",
        "    timestamp = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    data = {\n",
        "        'parameters': params,\n",
        "        'method': method,\n",
        "        'fire_dataset': calibration_fire,\n",
        "        'timestamp': timestamp\n",
        "    }\n",
        "    \n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "    \n",
        "    print(f\"Parameters saved to {file_path}\")\n",
        "\n",
        "def load_model_parameters(file_path='calibrated_params.json'):\n",
        "    \"\"\"Load calibrated parameters from JSON file\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"Loaded parameters calibrated on {data['fire_dataset']} using {data['method']}\")\n",
        "        return data['parameters']\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File {file_path} not found.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error decoding JSON from {file_path}.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c2e76f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save parameters from both methods\n",
        "if best_params:\n",
        "    save_model_parameters(best_params, 'Genetic Algorithm', 'ga_params.json')\n",
        "    \n",
        "if bayesian_params:\n",
        "    save_model_parameters(bayesian_params, 'Bayesian Estimation', 'bayes_params.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1445b1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a43af03",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b590fd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7756a2a2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
